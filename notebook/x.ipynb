{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8af34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All images resized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "root_dir = \"PotatoData/train\"   # replace with your dataset path\n",
    "img_size = (224, 224)  # YOLO cls default\n",
    "\n",
    "def resize_images(folder):\n",
    "    for subdir, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert(\"RGB\")\n",
    "                    img = img.resize(img_size)\n",
    "                    img.save(img_path)  # overwrite\n",
    "                except Exception as e:\n",
    "                    print(f\"Error resizing {img_path}: {e}\")\n",
    "\n",
    "# Apply to all sets\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    resize_images(os.path.join(root_dir, split))\n",
    "\n",
    "print(\"✅ All images resized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7778107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.201  Python-3.11.4 torch-2.8.0+cpu CPU (AMD Ryzen 5 5600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=PotatoData/train, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\runs\\classify\\train5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "WARNING Dataset 'split=train' not found at D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train\\train\n",
      "Found 10574 images in subdirectories. Attempting to split...\n",
      "Splitting D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train (2 classes, 10574 images) into 80% train, 20% val...\n",
      "Split complete in D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split \n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\train... found 8458 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\val... found 2116 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 8.53.1 MB/s, size: 66.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\train... 8458 images, 0 corrupt: 100% ━━━━━━━━━━━━ 8458/8458 631.9it/s 13.4s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 10.32.6 MB/s, size: 70.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\val... 2116 images, 0 corrupt: 100% ━━━━━━━━━━━━ 2116/2116 720.3it/s 2.9s<0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mD:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\runs\\classify\\train5\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/20         0G      0.192         10        224: 100% ━━━━━━━━━━━━ 529/529 1.9it/s 4:32<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.8it/s 36.8s0.5ss\n",
      "                   all      0.994          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/20         0G    0.08428         10        224: 100% ━━━━━━━━━━━━ 529/529 1.9it/s 4:33<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.9it/s 35.4s0.5ss\n",
      "                   all      0.986          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/20         0G     0.0968         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:17<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.1it/s 32.6s0.5ss\n",
      "                   all      0.974          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/20         0G    0.07554         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:07<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.1it/s 32.3s0.5ss\n",
      "                   all      0.989          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/20         0G    0.04611         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:11<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 33.4s0.5ss\n",
      "                   all      0.993          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/20         0G    0.04329         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:10<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 33.3s0.5ss\n",
      "                   all      0.996          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/20         0G    0.03527         10        224: 100% ━━━━━━━━━━━━ 529/529 2.0it/s 4:21<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.9it/s 34.9s0.6ss\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/20         0G    0.02784         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:16<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.9it/s 34.5s0.5ss\n",
      "                   all      0.996          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/20         0G    0.02643         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:16<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 32.8s0.6ss\n",
      "                   all      0.997          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/20         0G    0.01879         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:16<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 33.7s0.5ss\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/20         0G    0.02037         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:18<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 34.3s0.6ss\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/20         0G    0.01463         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:13<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.1it/s 31.6s0.5ss\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/20         0G    0.01476         10        224: 100% ━━━━━━━━━━━━ 529/529 2.0it/s 4:21<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.9it/s 35.9s0.5ss\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/20         0G    0.01068         10        224: 100% ━━━━━━━━━━━━ 529/529 2.0it/s 4:23<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.9it/s 35.6s0.5ss\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/20         0G   0.008318         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:17<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 34.2s0.5ss\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/20         0G   0.007665         10        224: 100% ━━━━━━━━━━━━ 529/529 2.0it/s 4:28<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.9it/s 35.5s0.5ss\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/20         0G   0.006053         10        224: 100% ━━━━━━━━━━━━ 529/529 2.0it/s 4:29<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.9it/s 35.1s0.5ss\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/20         0G   0.005417         10        224: 100% ━━━━━━━━━━━━ 529/529 2.0it/s 4:22<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.8it/s 36.4s0.5ss\n",
      "                   all      0.997          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/20         0G   0.006717         10        224: 100% ━━━━━━━━━━━━ 529/529 2.0it/s 4:20<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 34.1s0.5ss\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/20         0G   0.004222         10        224: 100% ━━━━━━━━━━━━ 529/529 2.1it/s 4:18<0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 2.0it/s 33.7s0.5ss\n",
      "                   all      0.998          1\n",
      "\n",
      "20 epochs completed in 1.632 hours.\n",
      "Optimizer stripped from D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\runs\\classify\\train5\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\runs\\classify\\train5\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\runs\\classify\\train5\\weights\\best.pt...\n",
      "Ultralytics 8.3.201  Python-3.11.4 torch-2.8.0+cpu CPU (AMD Ryzen 5 5600H with Radeon Graphics)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING Dataset 'split=train' not found at D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train\\train\n",
      "Found 10574 images in subdirectories. Attempting to split...\n",
      "Splitting D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train (2 classes, 10574 images) into 80% train, 20% val...\n",
      "Split complete in D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split \n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\train... found 10116 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\train_split\\val... found 3774 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 67/67 1.8it/s 37.1s0.6ss\n",
      "                   all      0.999          1\n",
      "Speed: 0.0ms preprocess, 4.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\runs\\classify\\train5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022EC2BB4690>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9995274245738983\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9990548491477966, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9995274245738983}\n",
       "save_dir: WindowsPath('D:/USER/OneDrive/Desktop/Final_yr/notebook/runs/classify/train5')\n",
       "speed: {'preprocess': 0.0005253308208336674, 'inference': 4.68518908317987, 'loss': 3.317580844446425e-05, 'postprocess': 7.759926049853015e-05}\n",
       "task: 'classify'\n",
       "top1: 0.9990548491477966\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# load classification model (ResNet-like backbone)\n",
    "model = YOLO(\"yolov8n-cls.pt\")\n",
    "\n",
    "# train\n",
    "model.train(\n",
    "    data=\"PotatoData/train\" ,\n",
    "    epochs=20,\n",
    "    imgsz=224,\n",
    "    batch=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ada35d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['epoch', 'time', 'train/loss', 'metrics/accuracy_top1',\n",
      "       'metrics/accuracy_top5', 'val/loss', 'lr/pg0', 'lr/pg1', 'lr/pg2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load YOLO training logs\n",
    "df = pd.read_csv(\"runs/classify/train5/results.csv\")\n",
    "\n",
    "# Show available columns\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d801b044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plots saved as loss_curve.png and accuracy_curve.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load logs\n",
    "df = pd.read_csv(\"runs/classify/train5/results.csv\")\n",
    "\n",
    "# 📉 Loss Curve\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df[\"epoch\"], df[\"train/loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(df[\"epoch\"], df[\"val/loss\"], label=\"Validation Loss\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"loss_curve.png\")   # ✅ saves plot\n",
    "plt.close()\n",
    "\n",
    "# 📈 Accuracy Curve\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df[\"epoch\"], df[\"metrics/accuracy_top1\"], label=\"Top-1 Accuracy\", marker=\"o\")\n",
    "plt.plot(df[\"epoch\"], df[\"metrics/accuracy_top5\"], label=\"Top-5 Accuracy\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"accuracy_curve.png\")   # ✅ saves plot\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ Plots saved as loss_curve.png and accuracy_curve.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e74637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.201  Python-3.11.4 torch-2.8.0+cpu CPU (AMD Ryzen 5 5600H with Radeon Graphics)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING Dataset 'split=train' not found at D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test\\train\n",
      "Found 1807 images in subdirectories. Attempting to split...\n",
      "Splitting D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test (2 classes, 1807 images) into 80% train, 20% val...\n",
      "Split complete in D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test_split \n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test_split\\train... found 1444 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test_split\\val... found 363 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 8.41.4 MB/s, size: 65.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test_split\\val... 363 images, 0 corrupt: 100% ━━━━━━━━━━━━ 363/363 678.1it/s 0.5s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test_split\\val.cache\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 23/23 5.7it/s 4.0s0.2s\n",
      "                   all          1          1\n",
      "Speed: 0.0ms preprocess, 4.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\runs\\classify\\train52\u001b[0m\n",
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022EC06AE010>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 1.0\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 1.0, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n",
      "save_dir: WindowsPath('D:/USER/OneDrive/Desktop/Final_yr/notebook/runs/classify/train52')\n",
      "speed: {'preprocess': 0.001135812661823491, 'inference': 4.733812121157925, 'loss': 6.611566472998704e-05, 'postprocess': 0.0001746555742199633}\n",
      "task: 'classify'\n",
      "top1: 1.0\n",
      "top5: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set (default) or specify test set\n",
    "metrics = model.val(data=\"PotatoData/test\")\n",
    "\n",
    "print(metrics)  # prints all metrics (top1_acc, top5_acc, precision, recall, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc09aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 1.00\n",
      "Top-5 Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Get specific metrics\n",
    "print(f\"Top-1 Accuracy: {metrics.top1:.2f}\")\n",
    "print(f\"Top-5 Accuracy: {metrics.top5:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\USER\\OneDrive\\Desktop\\Final_yr\\notebook\\PotatoData\\test\\Potato\\1106c3fc-92cb-41a6-a6c6-8f08b9b45108___RS_HL-1914_flipTB_JPG.rf.db639c064704912a6ba43bd8b23be1bf.jpg: 224x224 Potato 1.00, Not_Potato 0.00, 9.0ms\n",
      "Speed: 5.1ms preprocess, 9.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: None\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Not_Potato', 1: 'Potato'}\n",
      "obb: None\n",
      "orig_img: array([[[129, 119, 142],\n",
      "        [126, 116, 139],\n",
      "        [129, 119, 142],\n",
      "        ...,\n",
      "        [116, 109, 130],\n",
      "        [112, 105, 126],\n",
      "        [104,  97, 118]],\n",
      "\n",
      "       [[125, 115, 138],\n",
      "        [122, 112, 135],\n",
      "        [126, 116, 139],\n",
      "        ...,\n",
      "        [116, 109, 130],\n",
      "        [117, 110, 131],\n",
      "        [113, 106, 127]],\n",
      "\n",
      "       [[128, 118, 141],\n",
      "        [126, 116, 139],\n",
      "        [131, 121, 144],\n",
      "        ...,\n",
      "        [114, 107, 128],\n",
      "        [116, 109, 130],\n",
      "        [112, 105, 126]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[152, 142, 158],\n",
      "        [153, 143, 159],\n",
      "        [158, 148, 164],\n",
      "        ...,\n",
      "        [153, 145, 162],\n",
      "        [140, 132, 149],\n",
      "        [137, 129, 146]],\n",
      "\n",
      "       [[151, 141, 157],\n",
      "        [149, 139, 155],\n",
      "        [153, 143, 159],\n",
      "        ...,\n",
      "        [148, 140, 157],\n",
      "        [136, 128, 145],\n",
      "        [133, 125, 142]],\n",
      "\n",
      "       [[155, 145, 161],\n",
      "        [153, 143, 159],\n",
      "        [158, 148, 164],\n",
      "        ...,\n",
      "        [144, 136, 153],\n",
      "        [131, 123, 140],\n",
      "        [126, 118, 135]]], shape=(640, 640, 3), dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: 'd:\\\\USER\\\\OneDrive\\\\Desktop\\\\Final_yr\\\\notebook\\\\PotatoData\\\\test\\\\Potato\\\\1106c3fc-92cb-41a6-a6c6-8f08b9b45108___RS_HL-1914_flipTB_JPG.rf.db639c064704912a6ba43bd8b23be1bf.jpg'\n",
      "probs: ultralytics.engine.results.Probs object\n",
      "save_dir: 'D:\\\\USER\\\\OneDrive\\\\Desktop\\\\Final_yr\\\\notebook\\\\runs\\\\classify\\\\train53'\n",
      "speed: {'preprocess': 5.086899996967986, 'inference': 9.020700003020465, 'postprocess': 0.05370000144466758}]\n"
     ]
    }
   ],
   "source": [
    "# results = model.predict(\"PotatoData/test/Not_Potato/01482fdd-5dfd-4190-bbc0-6189a3161fae___JR_HL-7983_JPG.rf.9820ed2a5dbe13e17857622ed16e20e3.jpg\")\n",
    "\n",
    "results = model.predict(\"PotatoData/test/Potato/1106c3fc-92cb-41a6-a6c6-8f08b9b45108___RS_HL-1914_flipTB_JPG.rf.db639c064704912a6ba43bd8b23be1bf.jpg\")\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
